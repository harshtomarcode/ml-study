[{"Question": "According to the text, what is a limitation of anecdotal evidence?", "Options": {"1": "It is often personal and may be misremembered or misrepresented.", "2": "It is expensive to collect.", "3": "It is not representative of the population.", "4": "It can be difficult to find."}, "Answer": "1", "Reason": "Anecdotal evidence is often personal and may be misremembered or misrepresented, which can lead to biased results."}, {"Question": "What is the difference between the \"mean\" and \"average\" of a set of values?", "Options": {"1": "The mean is the sum of the values divided by the number of values, while the average is a summary statistic that describes the typical value.", "2": "The mean and average are the same thing.", "3": "The average is the sum of the values divided by the number of values, while the mean is a summary statistic that describes the typical value.", "4": "The difference is not explained in the text."}, "Answer": "1", "Reason": "The text states that the mean is the sum of the values divided by the number of values, while the average is one of many summary statistics that might be used to describe the typical value of a set of values."}, {"Question": "In a study, what is the mean of a sample calculated as?", "Options": {"1": "The sum of the values divided by the number of values", "2": "The most frequently occurring value", "3": "The midpoint of the range", "4": "The sum of the squared differences from the mean divided by the number of values"}, "Answer": "1", "Reason": "The mean of a sample is calculated by dividing the sum of all the values in the sample by the number of values in the sample."}, {"Question": "In statistics, what is the process for utilizing patterns, differences, and other features to address questions of interest, while also checking for inconsistencies and limitations?", "Options": {"1": "Hypothesis testing", "2": "Exploratory data analysis", "3": "Descriptive statistics", "4": "Regression analysis"}, "Answer": "2", "Reason": "Exploratory data analysis involves examining the data to identify patterns, differences, and other features that address the questions of interest, while also checking for inconsistencies and limitations."}, {"Question": "Which of the following is NOT a limitation of anecdotal evidence?", "Options": {"1": "Small number of observations", "2": "Selection bias", "3": "Estimation Bias", "4": "Inaccuracy"}, "Answer": "3", "Reason": "Estimation Bias is not a limitation of anecdotal evidence."}, {"Question": "Which of the following is NOT a limitation of anecdotal evidence?", "Options": {"1": "Small number of observations", "2": "Selection bias", "3": "Confirmation bias", "4": "Accuracy"}, "Answer": "4", "Reason": "Anecdotal evidence is often personal stories and therefore might be misremembered, misrepresented, or repeated inaccurately."}, {"Question": "In the context of statistical analysis, what is the main difference between cross-sectional studies and longitudinal studies?", "Options": {"1": "Cross-sectional studies collect data from a group repeatedly over time, while longitudinal studies capture a snapshot of a group at a point in time.", "2": "Longitudinal studies collect data from a group repeatedly over time, while cross-sectional studies capture a snapshot of a group at a point in time.", "3": "Cross-sectional studies are observational, while longitudinal studies are experimental.", "4": "Longitudinal studies are observational, while cross-sectional studies are experimental."}, "Answer": "2", "Reason": "Cross-sectional studies capture a snapshot of a group at a point in time, while longitudinal studies follow a group over time, collecting data repeatedly."}, {"Question": "Which of the following is the correct formula for calculating the mean of a population?", "Options": {"1": "\u00b5 = 1/n * \u2211(xi)", "2": "\u00b5 = 1/n * \u2211(yi)", "3": "\u00b5 = 1/n * \u2211(zi)", "4": "\u00b5 = 1/n * \u2211(x-y)"}, "Answer": "1", "Reason": "The mean of a population is calculated by summing up all the values in the population and dividing the sum by the number of values in the population."}, {"Question": "Which of the following is a measure of the spread of a set of values?", "Options": {"1": "Mean", "2": "Variance", "3": "Mode", "4": "Median"}, "Answer": "2", "Reason": "Variance measures the average of the squared deviations from the mean."}, {"Question": "Variance is a measure of the spread of a distribution. The variance of a set of values is calculated using the formula:?", "Options": {"1": "\u03c32 = 1 / n \u2211(xi \u2212 \u00b5)2", "2": "\u03c32 = 1 / n \u2211(xi + \u00b5)2", "3": "\u03c32 = n / \u2211(xi \u2212 \u00b5)2", "4": "\u03c32 = n / \u2211(xi + \u00b5)2"}, "Answer": "1", "Reason": "Variance is calculated as the mean of the squared deviations from the mean."}, {"Question": "Which of the following is NOT a characteristic of a distribution?", "Options": {"1": "Central tendency", "2": "Outliers", "3": "Correlation", "4": "Spread"}, "Answer": "3", "Reason": "Correlation is not a characteristic of a distribution, while central tendency, outliers, and spread are."}, {"Question": "In the text, it mentions that variance is the sum of the square of deviations from the mean, divided by the number of values. Which of the following is the formula for variance?", "Options": {"1": "\u03c3^2 = \u2211(xi - \u00b5)^2/n", "2": "\u03c3^2 = \u2211(xi - \u00b5)^2/(n-1)", "3": "\u03c3^2 = \u2211(xi - \u00b5)^2", "4": "\u03c3^2 = \u2211(xi - \u00b5)/n"}, "Answer": "1", "Reason": "Variance is the mean squared deviation, which is why it is denoted \u03c32. The formula to calculate variance is \u03c3^2 = \u2211(xi - \u00b5)^2/n, where xi is the individual data point, \u00b5 is the mean, and n is the number of data points."}, {"Question": "What is the term used to describe the spread of a dataset?", "Options": {"1": "Variance", "2": "Mean", "3": "Standard deviation", "4": "Mode"}, "Answer": "1", "Reason": "Variance is used to describe the spread of a dataset, which is a measure of how much the data is dispersed from its mean."}, {"Question": "In the context of descriptive statistics, what does the term \"variance\" refer to?", "Options": {"1": "The most frequent value in a distribution", "2": "The probability that an outcome will occur", "3": "The mean squared deviation", "4": "The difference between the minimum and maximum values"}, "Answer": "3", "Reason": "Variance is a measure of spread that is calculated by summing the squared deviations from the mean"}, {"Question": "In the context of data analysis, which of the following is a measure of the spread of a distribution?", "Options": {"1": "Mean", "2": "Variance", "3": "Mode", "4": "Frequency"}, "Answer": "2", "Reason": "Variance is a statistical measure that quantifies the spread of a distribution by calculating the average of the squared deviations from the mean."}, {"Question": "What is the term used to describe the amount of variability in a set of values?", "Options": {"1": "Central tendency", "2": "Standard deviation", "3": "Mean", "4": " Variance"}, "Answer": "4", "Reason": "The amount of variability in a set of values is known as its variance, which is calculated by summing the squared deviations of each value from the mean, divided by the sample size."}, {"Question": "What is the term used to describe the squared deviation from the mean?", "Options": {"1": "Standard deviation", "2": "Variance", "3": "Covariance", "4": "Standard score"}, "Answer": "2", "Reason": "Variance is the mean of the squared deviations from the mean."}, {"Question": "What is the mathematical description of variance?", "Options": {"1": "The mean of the squared differences from the mean", "2": "The square of the standard deviation", "3": "The mean of the absolute differences from the mean", "4": "The standard deviation of the squared differences from the mean"}, "Answer": "1", "Reason": "Variance is calculated by taking the average of the squared differences between each data point and the mean."}, {"Question": "The text explains that biased large classes would be oversampled while observing class size distribution from a random sample of students. Which approach can be applied to estimate the actual distribution of class sizes in such cases?", "Options": {"1": "Increasing sample size", "2": "Removing large classes from the sample", "3": "Applying appropriate transformation to the skewed data", "4": "Ignoring the bias"}, "Answer": "3", "Reason": "An appropriate transformation can unbias the observed class size distribution and recover the actual distribution of class sizes."}, {"Question": "The mean of an exponential distribution is determined by which parameter?", "Options": {"1": "The x-value", "2": "The y-value", "3": "The slope", "4": "The intercept"}, "Answer": "1", "Reason": "The mean of an exponential distribution is 1/\u03bb, where \u03bb is the parameter of the distribution."}, {"Question": "Which of the following statements accurately describes the mean class size perceived by the Dean and the students in the study?", "Options": {"1": "Both the Dean and the students perceived the average class size to be 24.", "2": "The Dean perceived a higher average class size than the students.", "3": "The Dean perceived a lower average class size than the students.", "4": "The average class size perceived by the Dean and the students was the same, but the perceived distribution differed."}, "Answer": "4", "Reason": "The Dean perceived the average class size to be 24 based on the sample mean of grouped data, while students perceived it to have a higher mean, but the actual distribution could not be found due to biased sampling."}, {"Question": "Why is the complementary CDF of an exponential distribution a straight line on a log-y scale?", "Options": {"1": "The mean of the distribution is the inverse of the slope.", "2": "The median of the distribution is the inverse of the slope.", "3": "The formula for the distribution specifies a straight line.", "4": "The slope of the line is equal to the parameter of the distribution."}, "Answer": "4", "Reason": "The log of the complementary CDF is linear with slope negative lambda, where lambda is the parameter of the exponential distribution."}, {"Question": "In the context of selecting students to participate in a study, what is the issue known as selection bias?", "Options": {"1": "When the selection process favors certain groups of individuals over others.", "2": "When the sample size is too small to make meaningful inferences.", "3": "When the data collection method is flawed and introduces bias.", "4": "When the results of the study are not generalizable to the population of interest."}, "Answer": "1", "Reason": "Selection bias occurs when the selection process favors certain groups of individuals over others, leading to a sample that may not accurately represent the population of interest."}, {"Question": "The text describes how the distribution of class sizes perceived by students can be biased. What is the reason for this bias?", "Options": {"1": "Students often underestimate the size of their classes.", "2": "Students tend to interact with the same students throughout the semester.", "3": "The chance of overtaking a runner, or being overtaken, is proportional to the difference in speeds.", "4": "The distribution of birth weights tends to resemble the familiar 'bell curve'."}, "Answer": "3", "Reason": "The text states that 'The chance of overtaking a runner, or being overtaken, is proportional to the difference in speeds.', which suggests that it is more likely to encounter people with different speeds during a race."}, {"Question": "Which of the following is the correct formula for calculating the mean of a probability mass function (PMF)?", "Options": {"1": "Mean = \u03a3(x * P(x))", "2": "Mean = \u03a3(P(x))", "3": "Mean = \u03a3(x ** 2 * P(x))", "4": "Mean = \u03a3(x / P(x))"}, "Answer": "1", "Reason": "The mean of a PMF is calculated as the sum of each possible value multiplied by its probability."}, {"Question": "Suppose we have a population of class sizes with an observed distribution. Which transformation can be applied to the distribution of observed class sizes to estimate the distribution of actual class sizes?", "Options": {"1": "Centering", "2": "Standardization", "3": "Unbiasing", "4": "Normalization"}, "Answer": "3", "Reason": "Unbiasing is the transformation applied to the observed distribution to estimate the distribution of actual class sizes by reducing oversampling bias."}, {"Question": "Suppose that you are above average in weight, but way above average in height. How would you determine if you are relatively light for your height?", "Options": {"1": "Select a cohort of people the same height and construct a conditional distribution of their weights.", "2": "Use the distribution of heights and weights to compute a conditional probability.", "3": "Apply a statistical test to compare your weight to the average weight for your height.", "4": "Calculate the correlation coefficient between height and weight."}, "Answer": "1", "Reason": "Conditional distributions are used to describe the distribution of a subset of the data selected according to a condition. In this case, you would select a cohort of people who are the same height as you and construct a CDF of weight for those people."}, {"Question": "If the average class size as determined by the Dean is 24, and a survey of students yields a seemingly higher average class size, what is the potential bias present in the survey?", "Options": {"1": "Oversampling of smaller classes", "2": "Oversampling of larger classes", "3": "Underestimation of actual class size", "4": "Inaccurate reporting by students"}, "Answer": "2", "Reason": "Sampling of students oversamples larger classes, leading to a higher perceived average class size."}, {"Question": "What is the formula for the CDF of the Pareto distribution?", "Options": {"1": "1 - (1-\u03b1)^x/xm", "2": "1 - (1-\u03b1)^x", "3": "1 - (1-\u03b1)^x/xm", "4": "1 - (1-x/xm)^\u03b1"}, "Answer": "1", "Reason": "The CDF of the Pareto distribution is 1 - (1-\u03b1)^x/xm where xm is the minimum possible value and \u03b1 determines the shape of the distribution."}, {"Question": "Which of the following transformations would make the Weibull distribution look like a straight line?", "Options": {"1": "log(x) vs. log(CDFy)", "2": "log(x) vs. log(1-CDFy)", "3": "x vs. CDFy", "4": "y vs. log(x)"}, "Answer": "1", "Reason": "Taking the log of both the x and y axes yields a straight line with slope -\u03b1 and intercept \u03b1 log xm."}, {"Question": "The Pareto distribution has a characteristic shape on a log-log scale. What is it?", "Options": {"1": "A straight line with a positive slope.", "2": "Exponential decay.", "3": "A straight line with a negative slope.", "4": "A quadratic parabola."}, "Answer": "1", "Reason": "A straight line with a negative slope indicates that the CCDF of a Pareto distribution is a straight line with a positive slope on a log-log scale."}, {"Question": "The text states that the empirical distribution of the interarrival times of student birthdays may not exactly fit an exponential distribution. What is a common reason for this?", "Options": {"1": "Birthdays are not distributed uniformly throughout the year", "2": "Students tend to lie about their birthdays", "3": "Data is only collected from students with the same birth month", "4": "The sample size is too small"}, "Answer": "1", "Reason": "The assumption that a birth is equally likely at any time of the day is usually not true."}, {"Question": "You conduct a sample, compute the interarrival times in days, and plot the CCDF on a log-y scale. Does it look like an exponential distribution?", "Options": {"1": "Yes, it does because the CCDF of an exponential distribution on a log-y scale is a straight line.", "2": "No, it does because the CCDF of an exponential distribution on a log-y scale is a curve.", "3": "Yes, it does because the CCDF of an exponential distribution on a linear-y scale is a straight line.", "4": "No, it does because the CCDF of a Pareto distribution on a log-y scale is a straight line."}, "Answer": "1", "Reason": "The CCDF of an exponential distribution on a log-y scale is a straight line because the CDF of an exponential distribution is a simple exponential function, and taking the log of a simple exponential function results in a linear function."}, {"Question": "What is the parameter of the Pareto distribution that determines its location?", "Options": {"1": "\u03b1", "2": "xm", "3": "\u03bb", "4": "\u03c3"}, "Answer": "2", "Reason": "xm is the minimum possible value of the Pareto distribution and thus determines its location."}, {"Question": "Which is the correct formula for false negative rate?", "Options": {"1": "FN/(FN+TP)", "2": "FN/(TN+FN)", "3": "FN/(FP+FN)", "4": "TN/(TN+FN)"}, "Answer": "2", "Reason": "False negative rate is the number of false negatives divided by the number of actual positives."}, {"Question": "What is the formula for calculating the median of the Pareto distribution?", "Options": {"1": "xm21/\u03b1", "2": "\u03b121/xm", "3": "\u03b1xm2", "4": "xm\u03b12"}, "Answer": "1", "Reason": "The median of the Pareto distribution is given by xm21/\u03b1, where  xm is the minimum possible value and \u03b1 is the shape parameter."}, {"Question": "Pareto distribution has a characteristic shape on a log-log scale. What does it look like?", "Options": {"1": "Straight line", "2": "Parabola", "3": "Hyperbola", "4": "Exponential curve"}, "Answer": "1", "Reason": "On a log-log scale, the CCDF of a Pareto distribution looks like a straight line with a slope of -\u03b1 and intercept of \u03b1 log xm, where \u03b1 and xm are the parameters of the distribution."}, {"Question": "Which of the following transformations makes a Weibull distribution look like a straight line?", "Options": {"1": "Log-log", "2": "Log-linear", "3": "Linear-log", "4": "Linear-linear"}, "Answer": "1", "Reason": "The Weibull distribution can be transformed into a straight line by taking the log of both the x and y values, resulting in a log-log plot."}, {"Question": "Which of the following is a key concept in Bayesianism?", "Options": {"1": "Degrees of belief", "2": "Frequencies of events", "3": "Set of identical trials", "4": "Universality of probability"}, "Answer": "1", "Reason": "Bayesianism defines probability as a degree of belief that an event will occur, while frequentism defines it in terms of relative frequencies of events over numerous repetitions of an experiment, which is not always applicable."}, {"Question": "Which of the following is the formula for calculating the probability of either event A or B, but not both?", "Options": {"1": "P(A or B) = P(A) + P(B)", "2": "P(A or B) = P(A) - P(B)", "3": "P(A or B) = P(A) + P(B) - P(A and B)", "4": "P(A or B) = P(A) - P(B) + P(A and B)"}, "Answer": "3", "Reason": "The probability of A or B, but not both, is calculated by adding the probabilities of each event and subtracting the probability of their intersection."}, {"Question": "According to the text, what is the probability of getting at least one 6 when rolling two dice?", "Options": {"1": "1/6", "2": "1/12", "3": "1/36", "4": "1/6"}, "Answer": "4", "Reason": "The probability of getting at least one 6 is equal to 1 minus the probability of not getting any sixes, which is (5/6)^2."}, {"Question": "According to Bayesian probability, what factors determine the probability of an event occurring?", "Options": {"1": "State of knowledge", "2": "Frequency of occurrence", "3": "Historical data", "4": "Number of trials"}, "Answer": "1", "Reason": "Bayesian probability defines probability as a degree of belief that an event will occur, which can be influenced by a person's state of knowledge."}, {"Question": "What is the probability that one of the dice has a 6, if two dice are rolled and the total is 8?", "Options": {"1": "5/12", "2": "1/4", "3": "1/3", "4": "1/6"}, "Answer": "1", "Reason": "The probability of getting a total of 8 is 5/36. The probability of getting a 6 on one dice is 1/6. So, the probability of getting a 6 on one dice and a total of 8 is 5/36 * 1/6 = 5/216. The probability of getting a total of 8 and not getting a 6 on either dice is 30/36 * 5/6 * 5/6 = 5/36. Therefore, the probability of getting a 6 on one dice given that the total is 8 is (5/216) / (5/216 + 5/36) = 5/12."}, {"Question": "In Bayesian probability, what is the term used for the probability of an event before any evidence is considered?", "Options": {"1": "Posterior probability", "2": "Prior probability", "3": "Conditional probability", "4": "Joint probability"}, "Answer": "2", "Reason": "In Bayesian probability, the prior probability represents the probability of an event before any evidence is taken into account."}, {"Question": "What is the probability that a die roll will result in a 6 if the total of two dice rolls is 8?", "Options": {"1": "1/12", "2": "1/6", "3": "1/2", "4": "1/3"}, "Answer": "2", "Reason": "Since the dice are independent, the probability of rolling a 6 on one die is equal to the probability of rolling a 6 on a single die, which is 1/6."}, {"Question": "What is the probability that a family with two children will have two girls, assuming that the probability of having a girl is 50% and the births are independent events?", "Options": {"1": "0.125", "2": "0.25", "3": "0.5", "4": "0.75"}, "Answer": "2", "Reason": "The probability of having two girls is (0.5) * (0.5) = 0.25, assuming independence of the two trials."}, {"Question": "According to Bayes's theorem, what is the probability of an event B occurring after event A has occurred?", "Options": {"1": "P(B|A)", "2": "P(A|B)", "3": "P(B|A) * P(A) / P(B)", "4": "P(B) * P(A|B) / P(A)"}, "Answer": "3", "Reason": "Bayes's theorem states that P(B|A) = P(B) * P(A|B) / P(A)"}, {"Question": "According to Bayesianism, what can be applied to determine the probability of an event occurring?", "Options": {"1": "A set of identical trials", "2": "A degree of belief", "3": "A sample mean", "4": "A frequency distribution"}, "Answer": "2", "Reason": "Bayesianism is a statistical approach that defines probability as a degree of belief instead of a frequency or a sample mean."}, {"Question": "Suppose the same test is applied to a population where the actual rate of drug use is 1%. What is the probability that someone who tests positive is actually a drug user?", "Options": {"1": "0.01", "2": "0.05", "3": "0.76", "4": "0.99"}, "Answer": "2", "Reason": "According to the text, the probability of a false positive is 1%. This means that for every 100 people who test positive, only 1 of them actually used drugs. So, if the actual rate of drug use is 1%, the probability that someone who tests positive is actually a drug user is 1 / 100 = 0.01, i.e., option 2."}, {"Question": "When conducting a hypothesis test, what is the probability of a false positive when the threshold is 5%?", "Options": {"1": "0.05", "2": "0.95", "3": "0.10", "4": "0.20"}, "Answer": "1", "Reason": "The probability of a false positive is equal to the chosen threshold, which is 5%."}, {"Question": "In hypothesis testing, which of the following choices is the correct definition of a p-value?", "Options": {"1": "The probability of the observed effect under the null hypothesis", "2": "The probability of the null hypothesis under the observed effect", "3": "The probability of the observed effect under the alternative hypothesis", "4": "The probability of the alternative hypothesis under the observed effect"}, "Answer": "1", "Reason": "The p-value is the probability of observing a test statistic as extreme as, or more extreme than, the one that was actually observed, assuming that the null hypothesis is true."}, {"Question": "In hypothesis testing, the null hypothesis is:", "Options": {"1": "Model based on the assumption that the apparent effect was actually due to chance.", "2": "Model based on the assumption that the apparent effect was actually real.", "3": "Model based on the assumption that there is an effect, but it is smaller than what was observed.", "4": "Model based on the assumption that there is no effect whatsoever."}, "Answer": "1", "Reason": "The null hypothesis is a model of the system based on the assumption that the apparent effect was actually due to chance."}, {"Question": "What happens to the variance of the sample mean as the sample size, n, increases?", "Options": {"1": "Increases", "2": "Decreases", "3": "Stays the same", "4": "Cannot be determined from the provided context"}, "Answer": "2", "Reason": "As the sample size increases, the sample mean becomes more precise and its variance decreases."}, {"Question": "In hypothesis testing, if a p-value is obtained using a distribution derived from the null hypothesis, what is the probability of committing a Type I error?", "Options": {"1": "1 - Type I error probability", "2": "The probability of the null hypothesis being true", "3": "\u03b1", "4": "1"}, "Answer": "3", "Reason": "Alpha (\u03b1) is the pre-defined acceptable probability of making a Type I error, which is the probability of rejecting the null hypothesis while it is true."}, {"Question": "In hypothesis testing, what is the impact of decreasing the threshold for the p-value?", "Options": {"1": "Increases the chances of type I error", "2": "Decreases the chances of type II error", "3": "Increases the chances of type II error", "4": "No effect"}, "Answer": "1", "Reason": "Decreasing the p-value threshold means we are accepting higher probability values as being statistically significant, which increases the chances of rejecting the null hypothesis even when it is true (i.e., a false positive or type I error)."}, {"Question": "What happens to the variance of the sample mean as the sample size, n, increases?", "Options": {"1": "It increases", "2": "It decreases", "3": "It remains the same", "4": "It decreases and then increases"}, "Answer": "2", "Reason": "By applying the rule of variance for multiple independent random variables, the variance of the sample mean decreases as 1/n, where n is the sample size."}, {"Question": "According to the Central Limit Theorem, as the sample size n increases, what happens to the variance of the sample mean?", "Options": {"1": "It increases proportionally to n", "2": "It decreases proportionally to n", "3": "It decreases proportionally to n^2", "4": "It remains constant"}, "Answer": "3", "Reason": "According to the Central Limit Theorem, the variance of the sample mean decreases proportionally to n."}, {"Question": "As the number of terms in a sample mean increases, what happens to the variance of the sample mean?", "Options": {"1": "It increases as a square law", "2": "It decreases as a square law", "3": "It increases as the number of terms", "4": "It decreases as the number of terms"}, "Answer": "2", "Reason": "As the number of terms (n) in a sample mean increases, the variance of the sample mean (\u03c3\u00b2) decreases as 1/n. This is a consequence of the Central Limit Theorem, which states that the distribution of sample means approaches a normal distribution as n increases, and the variance of a normal distribution is proportional to 1/n."}, {"Question": "In hypothesis testing, what is the interpretation of a p-value less than \u03b1?", "Options": {"1": "The effect is statistically significant.", "2": "The effect is not statistically significant.", "3": "The effect is probably due to chance.", "4": "The effect is definitely due to chance."}, "Answer": "1", "Reason": "By convention, a p-value less than \u03b1 indicates that the effect is considered statistically significant, meaning it is unlikely to have occurred by chance."}, {"Question": "According to the provided text, how is the chi-square test statistic most commonly calculated?", "Options": {"1": "\u2211i(Oi - Ei)2 / Ei", "2": "\u2211i(Ei - Oi)2 / Ei", "3": "\u2211i(Ei + Oi)2 / Ei", "4": "\u2211i(OiEi)2 / Ei"}, "Answer": "1", "Reason": "The chi-square test statistic is calculated as the sum of the squared differences between the observed and expected values, divided by the expected value for each cell."}, {"Question": "Which formula correctly calculates the chi-square statistic for a given set of data?", "Options": {"1": "\u2211 (Oi - Ei) / Ei", "2": "\u2211 (Ei - Oi) / Oi", "3": "\u2211 (Oi + Ei) / Ei", "4": "\u2211 (Ei + Oi) / Oi"}, "Answer": "1", "Reason": "The chi-square statistic is calculated by summing the squared deviations between the observed and expected values, divided by the expected values."}, {"Question": "Which of the following is the formula for the chi-square test statistic?", "Options": {"1": "\u2211(Observed Value-Expected Value)^2", "2": "\u2211(Expected Value-Observed Value)^2", "3": "\u2211(Expected Value-Observed Value)/Observed Value^2", "4": "\u2211(Observed Value-Expected Value)/Expected Value^2"}, "Answer": "1", "Reason": "The chi-square test statistic is calculated by summing the squares of the differences between the observed and expected values, divided by the expected values."}, {"Question": "Which of the following statistics is an unbiased estimator of the variance of a normal distribution?", "Options": {"1": "S2/(n-2)", "2": "S2/(n-1)", "3": "S2/n", "4": "S2"}, "Answer": "2", "Reason": "The variance of a normal distribution is S2 and the unbiased estimator is S2 / (n - 1)."}, {"Question": "When using the chi-square test, what statistic is computed to measure the total deviation?", "Options": {"1": "Poisson mean", "2": "Chi-square statistic", "3": "Standard deviation", "4": "Maximum likelihood estimate"}, "Answer": "2", "Reason": "The chi-square statistic is used when conducting a chi-square test to measure the total deviation between the observed and expected values in a set of categorical data."}, {"Question": "Which of the following is NOT a type of con\ufb01dence interval?", "Options": {"1": "Bayesian con\ufb01dence interval", "2": "Predictive interval", "3": "Credible interval", "4": "Monte Carlo interval", "5": "Bootstrap interval"}, "Answer": "4", "Reason": "Monte Carlo interval is a type of simulation-based interval, not a con\ufb01dence interval."}, {"Question": "What is the formula for the chi-square statistic used in hypothesis testing?", "Options": {"1": "\u2211(Oi - Ei)", "2": "\u2211(Oi + Ei)", "3": "\u2211(Oi - Ei)2 / Ei", "4": "\u2211(Oi + Ei)2 / Ei"}, "Answer": "3", "Reason": "The chi-square statistic is calculated as the sum of the squared deviations between observed and expected values, divided by the expected values."}, {"Question": "What is the formula for computing the chi-square statistic?", "Options": {"1": "\u2211 (Ei \u2212 Oi)2 / Ei", "2": "\u2211 (Oi \u2212 Ei)2 / Ei", "3": "\u2211 (Oi + Ei)2 / Ei", "4": "\u2211 (Oi \u2212 Ei) / Ei"}, "Answer": "2", "Reason": "The chi-square statistic is computed by summing the squared differences between the observed and expected values, divided by the expected values."}, {"Question": "According to the text, what is the formula for calculating the chi-squared test statistic?", "Options": {"1": "\u2211(Ei-Oi)\u00b2/Oi", "2": "\u2211(Oi-Ei)\u00b2/Ei", "3": "\u2211(Oi-Ei)\u00b2/n", "4": "\u2211(Oi-Ei)\u00b2/m"}, "Answer": "2", "Reason": "The chi-squared test statistic is calculated as the sum of the squared differences between the observed and expected values, divided by the expected values."}, {"Question": "What is the formula for calculating the slope of a linear regression line?", "Options": {"1": "Cov(X, Y) / Var(Y)", "2": "Var(X) / Cov(X, Y)", "3": "Var(Y) / Cov(X, Y)", "4": "Cov(Y, X) / Var(X)"}, "Answer": "1", "Reason": "The slope of a linear regression line is calculated by dividing the covariance of the independent variable (X) and the dependent variable (Y) by the variance of the independent variable (X)."}, {"Question": "What is the formula for computing the slope in a linear least squares fit?", "Options": {"1": "Sum of (xi - x)(yi - y) / Sum of (xi - x)^2", "2": "Sum of (xi - y)(yi - x) / Sum of (xi - y)^2", "3": "Sum of (xi - y)(yi - x) / Sum of (xi - x)^2", "4": "Sum of (xi - x)(yi - y) / Sum of (xi - y)^2"}, "Answer": "1", "Reason": "The slope of a linear least squares fit is calculated as the sum of the products of the differences between each x-value and the mean of x-values and the differences between each y-value and the mean of y-values, divided by the sum of the squared differences between each x-value and the mean of x-values."}, {"Question": "What is the slope of a least squares fit?", "Options": {"1": "The value of the intercept", "2": "The value of alpha", "3": "The value of beta", "4": "The value of gamma"}, "Answer": "3", "Reason": "The slope of a least squares fit is the value of beta."}, {"Question": "What are some reasons to use the least squares method to estimate the parameters of a linear fit?", "Options": {"1": "It is the most accurate method.", "2": "It is the simplest method to compute.", "3": "It gives more weight to large residuals.", "4": "It works well for data that is normally distributed."}, "Answer": "2", "Reason": "The text states that the least squares method is 'quick, easy, and often good enough'. Therefore, it is reasonable to assume that it is the simplest method to compute."}, {"Question": "What is the purpose of squaring residuals in a least squares fit?", "Options": {"1": "To make the fit insensitive to the signs of the residuals", "2": "To give more weight to large residuals", "3": "To produce normally distributed residuals", "4": "To make the fit more efficient"}, "Answer": "2", "Reason": "Squaring gives larger residuals more weight, which can be useful in some applications."}, {"Question": "What is another way to estimate the slope of a linear relationship between variables?", "Options": {"1": "Linear regression", "2": "Maximum likelihood estimation", "3": "Ordinary least squares", "4": "Method of moments"}, "Answer": "1", "Reason": "Linear regression is a statistical method used to estimate the relationship between a dependent variable and one or more independent variables."}, {"Question": "Which of the following is the formula for slope in a linear least squares fit?", "Options": {"1": "Residuals/Y", "2": "Cov(X, Y)/Var(X)", "3": "Y-X/Cov(X, Y)", "4": "X-Y/Residuals"}, "Answer": "2", "Reason": "The slope of a linear least squares fit is calculated as the covariance of X and Y divided by the variance of X."}, {"Question": "What is the expression for calculating the estimated slope of a linear relationship between X and Y?", "Options": {"1": "Cov(X, Y)/Var(X)", "2": "Var(Y)/Cov(X, Y)", "3": "Var(X)/Cov(Y, X)", "4": "Cov(Y, X)/Var(X)"}, "Answer": "1", "Reason": "The estimated slope is calculated as the covariance between X and Y divided by the variance of X."}, {"Question": "What is the formula for the slope of a linear least squares fit?", "Options": {"1": "Var(X)/Cov(X,Y)", "2": "Cov(X,Y)/Var(X)", "3": "(Cov(X,Y) - Var(X))/Var(Y)", "4": "(Var(X) - Cov(X,Y))/Var(Y)"}, "Answer": "2", "Reason": "The slope is calculated as the covariance between X and Y divided by the variance of X."}, {"Question": "What are the three main reasons to minimize squared residuals?", "Options": {"1": "Squaring gives more weight to outliers and minimizes the error for most of the data, Squaring treats positive and negative residuals the same, and If the residuals are independent, random, and normally distributed, then the least squares fit is also the maximum likelihood estimator of the parameters.", "2": "Squaring treats positive and negative residuals the same, Squaring gives more weight to outliers, and the values of \u02c6\u03b1 and \u02c6\u03b2 that minimize the squared residuals can be computed efficiently.", "3": "Squaring treats positive and negative residuals the same, If the residuals are independent, random, and normally distributed, then the least squares fit is also the maximum likelihood estimator of the parameters, and the values of \u02c6\u03b1 and \u02c6\u03b2 that minimize the squared residuals can be computed efficiently.", "4": "The values of \u02c6\u03b1 and \u02c6\u03b2 that minimize the squared residuals can be computed efficiently, If the residuals are independent, random, and normally distributed, then the least squares fit is also the maximum likelihood estimator of the parameters, and Squaring gives more weight to outliers."}, "Answer": "3", "Reason": "Squaring treats positive and negative residuals the same, If the residuals are independent, random, and normally distributed, then the least squares fit is also the maximum likelihood estimator of the parameters, and the values of \u02c6\u03b1 and \u02c6\u03b2 that minimize the squared residuals can be computed efficiently."}, {"Question": "In the Monty Hall problem, what is the probability of winning if you switch your choice?", "Options": {"1": "1/3", "2": "1/2", "3": "2/3", "4": "0"}, "Answer": "2", "Reason": "There are 3 doors, and one of them has the prize. If you initially choose a door, the probability of choosing the correct door is 1/3. When you switch, you are essentially choosing one of the two remaining doors. Since one of those doors has the prize, the probability of winning is 1/2."}, {"Question": "Which type of probability is based on previous beliefs and experiences, and is updated as new information becomes available?", "Options": {"1": "Conditional probability", "2": "Prior probability", "3": "Posterior probability", "4": "Marginal probability"}, "Answer": "3", "Reason": "Posterior probability is a type of probability that takes into account the cumulative evidence of previous observations, and is updated as new data is collected"}, {"Question": "What is the purpose of a prior distribution in Bayesian statistics?", "Options": {"1": "To represent the probability distribution of the parameter before any data is observed", "2": "To represent the probability distribution of the parameter after data has been observed", "3": "To represent the joint probability distribution of the parameter and the data", "4": "To represent the conditional probability distribution of the data given the parameter"}, "Answer": "1", "Reason": "A prior distribution represents the probability distribution of a parameter before any data is observed."}, {"Question": "Which of the following is true about a normal distribution?", "Options": {"1": "It is always symmetric.", "2": "It is always bell-shaped.", "3": "It has a mean of 0 and a standard deviation of 1.", "4": "It is a type of discrete distribution."}, "Answer": "1", "Reason": "A normal distribution is a continuous distribution that is symmetric around its mean, with the tails of the distribution decreasing in frequency as the distance from the mean increases."}, {"Question": "Which of the following is NOT a characteristic of a normal distribution?", "Options": {"1": "Symmetrical", "2": "Bell-shaped", "3": "Mean = Median = Mode", "4": "Limited range"}, "Answer": "4", "Reason": "Normal distributions can have an infinite range of values, unlike some other distributions which may be limited to a specific interval."}, {"Question": "Which of the following is a characteristic of a normal distribution?", "Options": {"1": "Symmetric", "2": "Right-skewed", "3": "Left-skewed", "4": "All of the above"}, "Answer": "1", "Reason": "Normal distributions are bell-shaped curves. They are said to be symmetric because there is no skew in their data."}, {"Question": "In a probability experiment, what is the process of repeatedly selecting a single item from a population, noting the item, and returning it to the population before selecting the next item called?", "Options": {"1": "Sampling without replacement", "2": "Random sampling", "3": "Sampling with replacement", "4": "Systematic sampling"}, "Answer": "3", "Reason": "Sampling with replacement involves returning the item to the population before selecting the next item, ensuring that each item has an equal chance of being selected multiple times."}, {"Question": "Which of the following is NOT an operation that can be performed on distributions?", "Options": {"1": "Addition", "2": "Multiplication", "3": "Subtraction", "4": "Integration"}, "Answer": "3", "Reason": "Distributions can be added, multiplied, or integrated, but subtraction is not a valid operation on distributions."}, {"Question": "Which of the following is not a property of the normal distribution?", "Options": {"1": "Symmetric.", "2": "Bell-shaped.", "3": "Heavy tails.", "4": "Continuous."}, "Answer": "3", "Reason": "The normal distribution is not heavy-tailed."}, {"Question": "What is the concept of normalizing a distribution?", "Options": {"1": "Adjusting the values so that they sum to 1", "2": "Adjusting the values so that they have a mean of 0 and a standard deviation of 1", "3": "Adjusting the values so that they are all positive", "4": "Adjusting the values so that they are all bounded between 0 and 1"}, "Answer": "1", "Reason": "Normalization involves adjusting the values so that their sum adds up to 1, making it a probability distribution."}, {"Question": "Which of the following is used to measure the performance of a machine learning model on unseen data?", "Options": {"1": "Training metrics", "2": "Evaluation metrics", "3": "Classification metrics", "4": "Regression metrics"}, "Answer": "2", "Reason": "Evaluation metrics are used to assess the model's performance on new data that it has not been trained on."}, {"Question": "Which of the following is NOT a type of evaluation metric?", "Options": {"1": "Classification Metrics", "2": "Regression Metrics", "3": "Ranking Metrics", "4": "Model Tuning Metrics"}, "Answer": "4", "Reason": "Model Tuning Metrics is not a type of evaluation metric because it is used to select the best model from a set of models, while evaluation metrics are used to assess the performance of a single model on a given dataset."}, {"Question": "What is the key difference between hold-out validation and cross-validation?", "Options": {"1": "Hold-out validation uses the entire dataset for training and validation, while cross-validation splits the dataset into multiple subsets.", "2": "Cross-validation uses the entire dataset for training and validation, while hold-out validation splits the dataset into multiple subsets.", "3": "Hold-out validation is used for evaluating model performance, while cross-validation is used for selecting the best model.", "4": "Cross-validation is used for evaluating model performance, while hold-out validation is used for selecting the best model."}, "Answer": "1", "Reason": "Hold-out validation uses the entire dataset for training and then splits it into training and validation sets, while cross-validation splits the dataset into multiple subsets and iteratively trains and validates the model on different subsets."}, {"Question": "Which of the following is NOT a caution associated with the use of evaluation metrics?", "Options": {"1": "Difference between training metrics and evaluation metrics", "2": "Skewed dataset", "3": "Accuracy paradox", "4": "Efficient hyperparameter tuning"}, "Answer": "4", "Reason": "Efficient hyperparameter tuning is not a caution associated with the use of evaluation metrics. It is a method for improving the performance of machine learning models."}, {"Question": "Which of the following is a type of evaluation metric?", "Options": {"1": "Classification", "2": "Optimization", "3": "Validation", "4": "Estimation"}, "Answer": "1", "Reason": "Classification is a type of evaluation metric used to assess the performance of a machine learning model on a classification task."}, {"Question": "Which of the following is NOT a measure of performance in regression metrics?", "Options": {"1": "Mean squared error", "2": "Root mean squared error", "3": "Accuracy", "4": "R-squared"}, "Answer": "3", "Reason": "Accuracy, which is the ratio of correctly predicted observations to the total observations, is not a measure of performance in regression metrics."}, {"Question": "Which of the following is NOT a hyperparameter?", "Options": {"1": "Learning rate", "2": "Number of features", "3": "Optimizer", "4": "Activation function"}, "Answer": "2", "Reason": "Hyperparameters are parameters of the learning algorithm itself, whereas the number of features is a property of the dataset."}, {"Question": "What does the term 'hyperparameter' refer to in the context of machine learning?", "Options": {"1": "A parameter that is learned directly from the data", "2": "A parameter that is set before training and affects the model's performance", "3": "A metric used to evaluate the model's performance", "4": "A variable that is used to store intermediate results during training"}, "Answer": "2", "Reason": "Hyperparameters are parameters that control the learning process and are set before training begins."}, {"Question": "What is the correct formula for false positive rate?", "Options": {"1": "FP/(TN+TP)", "2": "FN/(FN+FP)", "3": "FP/(FN+FP)", "4": "FP/FP+TN"}, "Answer": "4", "Reason": "It is calculated as the number of false positives divided by total number of actual negatives."}, {"Question": "What is the difference between training metrics and evaluation metrics?", "Options": {"1": "Training metrics measure how well the model performs on the unseen data, while evaluation metrics measure how well the model performs on the training data.", "2": "Training metrics measure how well the model learns the training data, while evaluation metrics measure how well the model generalizes to new data.", "3": "Training metrics are computed on the training set, while evaluation metrics are computed on the validation set.", "4": "Both 2 and 3"}, "Answer": "4", "Reason": "Training metrics are computed on the training set to evaluate the model's ability to learn the training data, while evaluation metrics are computed on the validation set to evaluate the model's ability to generalize to new data."}, {"Question": "Which of the following is a method used for hyperparameter search?", "Options": {"1": "Grid search", "2": "Precision-recall", "3": "Random forest", "4": "A/B testing"}, "Answer": "1", "Reason": "Grid search is a method for searching through hyperparameter space and finding good configurations."}, {"Question": "Which of the following is a method for generating new data to evaluate a machine learning model during the prototyping phase?", "Options": {"1": "Hold-out validation", "2": "Linear regression", "3": "PCA", "4": "Apriori algorithm"}, "Answer": "1", "Reason": "Hold-out validation involves setting aside a portion of the training set for evaluation, ensuring that the model is evaluated on data it has not seen during training."}, {"Question": "What is the purpose of cross-validation in machine learning?", "Options": {"1": "To improve the accuracy of the model", "2": "To prevent overfitting", "3": "To evaluate the model on unseen data", "4": "To select the optimal hyperparameters"}, "Answer": "3", "Reason": "Cross-validation is used to estimate the generalization error of a model by repeatedly dividing the dataset into training and validation sets, ensuring that the model is evaluated on data it has not seen during training."}, {"Question": "What is the purpose of k-fold cross-validation in offline evaluation?", "Options": {"1": "To obtain new data for model evaluation", "2": "To determine the optimal hyperparameters for a model", "3": "To prevent overfitting of a model", "4": "To detect distribution drift"}, "Answer": "1", "Reason": "K-fold cross-validation is used to split a dataset into multiple folds, and the model is trained and evaluated on different combinations of these folds, providing a more robust estimate of the model's performance on unseen data."}, {"Question": "What is the process of using a subset of training data to assess the performance of a machine learning model called?", "Options": {"1": "Bootstrapping", "2": "Random search", "3": "Grid search", "4": "Cross-validation"}, "Answer": "4", "Reason": "Cross-validation is a method of dividing the training data into subsets and using one subset for evaluation while training the model on the remaining subsets."}, {"Question": "Which of the following is a type of hyperparameter?", "Options": {"1": "Number of features", "2": "Model parameter", "3": "Training epoch", "4": "Learning rate"}, "Answer": "1", "Reason": "Hyperparameters are parameters that are not learned by the training algorithm, and the number of features is one of them."}, {"Question": "Which of the following is a method used for evaluating the performance of a machine learning model on historical data?", "Options": {"1": "A/B testing", "2": "Regression analysis", "3": "Cross-validation", "4": "Multiarmed bandits"}, "Answer": "3", "Reason": "Cross-validation is a method used for evaluating the performance of a machine learning model on historical data, as it involves splitting the data into multiple subsets and iteratively using them for training and evaluation."}, {"Question": "In the context of model evaluation, what does 'distribution drift' refer to?", "Options": {"1": "The model's performance on new data is consistently better than on the training data.", "2": "The distribution of data used for training and evaluation changes over time.", "3": "The model is no longer performing as well as it did when it was first built.", "4": "The validation dataset is no longer representative of real-world data."}, "Answer": "2", "Reason": "Distribution drift occurs when the data distribution changes over time, affecting the model's performance."}, {"Question": "Which of the following is NOT a category of machine learning model evaluation?", "Options": {"1": "Offline evaluation", "2": "Online evaluation", "3": "In-progress evaluation", "4": "Hyperparameter search"}, "Answer": "3", "Reason": "In-progress evaluation is not a category of machine learning model evaluation. Offline evaluation, online evaluation, and hyperparameter search are the three main categories."}, {"Question": "What is the goal of a machine learning model evaluation?", "Options": {"1": "To select the best model for a given dataset.", "2": "To tune the model's hyperparameters.", "3": "To detect distribution drift.", "4": "To measure the model's performance on live data."}, "Answer": "1", "Reason": "The goal of a machine learning model evaluation is to select the best model for a given dataset, which then gets deployed to production and goes through further testing on live data."}, {"Question": "Which of the following formulas is used to calculate accuracy?", "Options": {"1": "FP/(FP+TN)", "2": "(TP+TN)/(FP+FN+TP+TN)", "3": "FP/(FN+FP)", "4": "TP/(FP+TN)"}, "Answer": "2", "Reason": "Accuracy is the ratio of correct predictions to the total number of predictions, which is represented by the formula (TP+TN)/(FP+FN+TP+TN)."}, {"Question": "What is the formula for AUC?", "Options": {"1": "Sensitivity + Specificity", "2": "Area under the ROC curve", "3": "Precision + Recall", "4": "Log-loss"}, "Answer": "2", "Reason": "AUC stands for the Area Under the Receiver Operating Characteristic Curve, which plots the sensitivity against the false positive rate at various classification thresholds."}, {"Question": "Which of the following is a metric used to measure the performance of binary classification models?", "Options": {"1": "Accuracy", "2": "Log-loss", "3": "AUC", "4": "All of the above"}, "Answer": "4", "Reason": "Accuracy, log-loss, and AUC are all commonly used metrics for evaluating the performance of binary classification models."}, {"Question": "What is the formula for calculating Confusion Matrix?", "Options": {"1": "FP/(TN+TP)", "2": "FN/(FN+FP)", "3": "FP/(FN+FP)", "4": "FP/FP+TN"}, "Answer": "1", "Reason": "Confusion Matrix is a table that summarizes the performance of a classification model on a set of test data for two or more classes."}, {"Question": "Which of the following is a metric used to measure the performance of classification models?", "Options": {"1": "Accuracy", "2": "Log-loss", "3": "AUC", "4": "All of the above"}, "Answer": "4", "Reason": "Accuracy, log-loss, and AUC are commonly used metrics for classification models."}, {"Question": "What is the mathematical formula for log-loss in binary classification?", "Options": {"1": "-N log p(y) + N log (1-p(y))", "2": "-N (y log p(y) + (1-y) log (1-p(y)))", "3": "-N (y log p(y) + (1-y) log (1-p(y))", "4": "-N (y log (1-p(y)) + (1-y) log p(y))"}, "Answer": "3", "Reason": "Log-loss is defined as the negative sum of the true label (y) multiplied by the log probability of the predicted label (p(y)) and (1-y) multiplied by the log probability of the predicted label (1-p(y))."}, {"Question": "Which of the following is the formula for accuracy?", "Options": {"1": "FP/(FN+FP)", "2": "FN/(FN+FP)", "3": "TP/(TP+TN)", "4": "FP/FN+FP"}, "Answer": "3", "Reason": "Accuracy is the ratio of correct predictions (true positives) to the total number of predictions."}, {"Question": "Which of the following is a measure of classification performance that incorporates the concept of probabilistic confidence?", "Options": {"1": "Accuracy", "2": "Confusion Matrix", "3": "Log-Loss", "4": "AUC"}, "Answer": "3", "Reason": "Log-Loss measures the cross entropy between the distribution of the true labels and the predictions, and is related to the concept of relative entropy, which measures the 'extra noise' that comes from using a predictor as opposed to the true labels."}, {"Question": "Which of the following is NOT a classification metric?", "Options": {"1": "Accuracy", "2": "Log-loss", "3": "Precision", "4": "AUC"}, "Answer": "4", "Reason": "AUC is a metric used in ranking, not classification."}, {"Question": "Which of the following is not a classification metric?", "Options": {"1": "Accuracy", "2": "AUC", "3": "Mean Absolute Error", "4": "Confusion Matrix"}, "Answer": "3", "Reason": "Mean Absolute Error is a regression metric, not a classification metric."}, {"Question": "What is the mathematical formula for precision?", "Options": {"1": "Total relevant items/Happy correct answers", "2": "Happy correct answers/Total items returned by ranker", "3": "Total items returned by ranker/Happy correct answers", "4": "Happy correct answers/Total relevant items"}, "Answer": "4", "Reason": "It is calculated as the number of results that are relevant divided by the total number of relevant results."}, {"Question": "What is the harmonic mean of precision and recall?", "Options": {"1": "Precision + Recall", "2": "Precision * Recall", "3": "2 * Precision * Recall / (Precision + Recall)", "4": "Precision - Recall"}, "Answer": "3", "Reason": "The harmonic mean is calculated as 2 times precision multiplied by recall divided by the sum of precision and recall."}, {"Question": "Which of the following is the correct formula for precision?", "Options": {"1": "TP+FP/TP+TN", "2": "# happy correct answers / # total items returned by ranker", "3": "# happy correct answers / # total relevant items", "4": "# retrieved relevant items / # total retrieved items"}, "Answer": "2", "Reason": "Precision is calculated as the number of true positives divided by the total number of retrieved items, which is usually represented as # happy correct answers / # total items returned by ranker."}, {"Question": "What is the difference between recall and precision?", "Options": {"1": "Recall measures the number of relevant items found, while precision measures the number of found items that are relevant.", "2": "Recall measures the number of found items that are relevant, while precision measures the number of relevant items found.", "3": "Precision measures the number of found items that are relevant, while recall measures the number of relevant items found.", "4": "Recall measures the number of relevant items not found, while precision measures the number of found items that are not relevant."}, "Answer": "3", "Reason": "Precision measures the proportion of correct predictions in the set of positive predictions, while recall measures the proportion of correct predictions in the set of actual positives."}, {"Question": "What is the formula for F1 score?", "Options": {"1": "precision * recall", "2": "harmonic mean of precision and recall", "3": "arithmetic mean of precision and recall", "4": "precision + recall"}, "Answer": "2", "Reason": "F1 score is calculated as the harmonic mean of precision and recall, which is a way of combining two numbers that tends toward the smaller of the two."}, {"Question": "According to the text, what metric can be used to combine precision and recall?", "Options": {"1": "NDCG", "2": "MAPE", "3": "RMSE", "4": "F1"}, "Answer": "4", "Reason": "F1 is calculated by taking the harmonic mean of precision and recall, which gives more weight to the smaller of the two values."}, {"Question": "Which of the following is the formula for precision?", "Options": {"1": "TP/(TP+FN)", "2": "FP/(FP+TN)", "3": "FP/(FN+FP)", "4": "TP/(TP+FP)"}, "Answer": "4", "Reason": "Precision is defined as the proportion of returned items that are actually relevant."}, {"Question": "According to the text, what is the mathematical formula for precision?", "Options": {"1": "TP/(TP+FP)", "2": "FP/(FN+FP)", "3": "FN/(FN+FP)", "4": "TP/(FN+TP)"}, "Answer": "1", "Reason": "Precision answers the question: Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant? It is calculated as the number of true positives divided by total number of predicted positives (TP+FP)."}, {"Question": "Which of the following formulas calculates precision?", "Options": {"1": "TN/(TN+FN)", "2": "TP/(FN+TP)", "3": "TP/(TP+FP)", "4": "TN/(TP+FP)"}, "Answer": "3", "Reason": "Precision answers the question, 'Out of the items that the ranker/classifier predicted to be relevant, how many are truly relevant?' Mathematically, precision is calculated as the number of true positives divided by the total number of positive predictions."}, {"Question": "What is the mathematical formula for recall?", "Options": {"1": "TP/(FN+FN)", "2": "TP/(TP+TN)", "3": "FP/(FN+FP)", "4": "FN/(FN+FP)"}, "Answer": "2", "Reason": "Recall answers the question, \u2018Out of all the items that are truly relevant, how many are found by the ranker/classifier?\u2019"}, {"Question": "How does cross-validation differ from hold-out validation?", "Options": {"1": "Cross-validation uses all the data for training, while hold-out validation does not.", "2": "Hold-out validation is computationally more expensive than cross-validation.", "3": "Cross-validation produces multiple estimates of performance, while hold-out validation produces only one estimate.", "4": "Cross-validation is used for hyperparameter tuning, while hold-out validation is not."}, "Answer": "3", "Reason": "Cross-validation generates multiple training and validation sets by dividing the training data into folds, while hold-out validation uses a single training set and a single validation set."}, {"Question": "Why is it necessary to evaluate a model on two different datasets?", "Options": {"1": "To ensure the model generalizes well to new data.", "2": "To detect overfitting.", "3": "To improve the accuracy of the model.", "4": "To reduce bias in the model's predictions."}, "Answer": "1", "Reason": "The model must be validated on data it has not previously seen to give an estimate of the generalization error, i.e., how well the model generalizes to new data."}, {"Question": "Which of the following is NOT a technique for evaluating machine learning models?", "Options": {"1": "Hold-out validation", "2": "Cross-validation", "3": "Feature engineering", "4": "Bootstrap"}, "Answer": "3", "Reason": "Feature engineering is a technique for improving the quality of the data, not for evaluating models."}, {"Question": "Which of the following is an important point for offline evaluation and model validation?", "Options": {"1": "Model validation involves evaluating new models on a separate dataset.", "2": "Cross-validation is used for hyperparameter tuning.", "3": "Hold-out validation is more computationally expensive than cross-validation.", "4": "Testing should be done on the same dataset used for training the model."}, "Answer": "1", "Reason": "Model validation involves evaluating new models on a separate dataset to avoid overfitting and ensure the model's generalization ability."}, {"Question": "What is the approximate ratio of unique instances in a bootstrapped dataset?", "Options": {"1": "0", "2": "25%", "3": "50%", "4": "63.2%"}, "Answer": "4", "Reason": "Due to replication, approximately two-thirds of the original dataset is expected to end up in the bootstrapped dataset."}, {"Question": "In the context of bootstrapping, what is the expected ratio of unique instances in the bootstrapped set?", "Options": {"1": "1 - 1/e", "2": "1/2", "3": "1 - 1 /e^2", "4": "1 / e"}, "Answer": "1", "Reason": "The expected ratio of unique instances in the bootstrapped set is approximately 1 - 1 / e, which is approximately 63.2%."}, {"Question": "What is the expected ratio of unique instances in a bootstrapped set?", "Options": {"1": "25%", "2": "50%", "3": "63.2%", "4": "75%"}, "Answer": "3", "Reason": "The expected ratio of unique instances in the bootstrapped set is approximately 1 \u2013 1/e \u2248 63.2%"}, {"Question": "Which of the following techniques resamples the data in a similar way to k-fold cross-validation?", "Options": {"1": "Hold-out validation", "2": "Bootstrapping", "3": "Jackknife", "4": "Stratified sampling"}, "Answer": "2", "Reason": "Both bootstrapping and k-fold cross-validation resample the data by randomly selecting subsets of the data to train and evaluate the model."}, {"Question": "In the context of model validation, what is the key difference between hyperparameter tuning and cross-validation?", "Options": {"1": "Hyperparameter tuning is used to select the best model type, while cross-validation is used to evaluate model performance.", "2": "Cross-validation is used to select the best model type, while hyperparameter tuning is used to evaluate model performance.", "3": "Hyperparameter tuning involves optimizing model settings, while cross-validation involves splitting data into training and validation sets.", "4": "Cross-validation involves optimizing model settings, while hyperparameter tuning involves splitting data into training and validation sets."}, "Answer": "3", "Reason": "Hyperparameter tuning involves optimizing model settings to improve performance, such as regularization parameters or learning rates. Cross-validation, on the other hand, involves splitting the data into training and validation sets to assess model performance across different subsets of the data."}, {"Question": "Which of the following is NOT a purpose of hyperparameter tuning?", "Options": {"1": "Preventing overfitting", "2": "Improving model capacity", "3": "Optimizing the loss function", "4": "Setting the number of features in the model"}, "Answer": "4", "Reason": "The number of features in the model is not a hyperparameter, but a structural property of the model."}, {"Question": "Which of the following is NOT a reason to use hyperparameter tuning?", "Options": {"1": "To prevent overfitting", "2": "To improve model accuracy", "3": "To reduce computational cost", "4": "To optimize model capacity"}, "Answer": "3", "Reason": "Hyperparameter tuning is used to find the optimal hyperparameters for a machine learning model, which can improve the accuracy of the model and prevent overfitting. It does not reduce computational cost, but rather may increase it."}, {"Question": "Which of the following is NOT a characteristic of hyperparameters?", "Options": {"1": "They control model capacity.", "2": "They are specified outside of the training procedure.", "3": "They are found through training.", "4": "They can have a significant impact on prediction accuracy."}, "Answer": "3", "Reason": "Hyperparameters are specified outside of the training procedure and are not found through training. They are set manually and are not learned by the model during the training phase."}, {"Question": "What is the relationship between the bootstrapped dataset and the original dataset?", "Options": {"1": "The bootstrapped dataset is a subset of the original dataset.", "2": "The bootstrapped dataset is a superset of the original dataset.", "3": "The bootstrapped dataset is a copy of the original dataset.", "4": "The bootstrapped dataset is unrelated to the original dataset."}, "Answer": "1", "Reason": "The bootstrapped dataset is created by randomly selecting data points from the original dataset with replacement, so it is a subset of the original dataset."}, {"Question": "Which of the following is the goal of smart hyperparameter tuning methods?", "Options": {"1": "To find the optimal hyperparameter settings with as few evaluations as possible", "2": "To evaluate all possible hyperparameter settings in parallel", "3": "To model the response surface of the hyperparameters", "4": "To choose between different model families"}, "Answer": "1", "Reason": "Smart hyperparameter tuning methods aim to reduce the number of evaluations needed to find the optimal hyperparameter settings."}, {"Question": "Which of the following is the reason why hyperparameter tuning is much harder than model training?", "Options": {"1": "It requires more data to be collected.", "2": "The quality of hyperparameters cannot be written down in a closed-form formula.", "3": "It is more computationally expensive.", "4": "It is more difficult to find the optimal values for hyperparameters."}, "Answer": "2", "Reason": "Hyperparameter tuning is harder because the quality of hyperparameters depends on the outcome of a black box (the model training process), and this cannot be written down in a closed-form formula."}, {"Question": "What is the main difference between smart hyperparameter tuning methods and dumb methods like grid search and random search?", "Options": {"1": "Smart methods are less parallelizable.", "2": "Smart methods require a list of candidate settings as input.", "3": "Smart methods can determine where to sample next without evaluating all possible points.", "4": "Smart methods are more computationally expensive."}, "Answer": "3", "Reason": "Smart hyperparameter tuning methods are able to determine where to sample next without evaluating all possible points, unlike dumb methods like grid search and random search."}, {"Question": "What is the key difference between grid search and smart search methods in hyperparameter tuning?", "Options": {"1": "Grid search requires a fixed grid of candidate settings, while smart search methods iteratively determine the next set of samples.", "2": "Grid search is more parallelizable than smart search methods.", "3": "Smart search methods use a mathematical formula to compute the response surface, while grid search does not.", "4": "Smart search methods only evaluate a random sample of points on the grid, while grid search evaluates all points."}, "Answer": "1", "Reason": "The text states that smart search methods pick a few hyperparameter settings, evaluate their quality, and then decide where to sample next, while grid search picks out a grid of hyperparameter values and evaluates every one of them."}, {"Question": "According to the text, what is one of the key differences between hyperparameter tuning and model training?", "Options": {"1": "Hyperparameter tuning can be written down in a closed-form formula.", "2": "Hyperparameter tuning is much easier than model training.", "3": "Hyperparameter tuning depends on the outcome of a black box process.", "4": "Hyperparameter tuning is only necessary for complex models."}, "Answer": "3", "Reason": "Hyperparameter tuning depends on the outcome of a black box process, while model training can be described using a mathematical formula."}, {"Question": "Which of the following is true about smart hyperparameter tuning methods?", "Options": {"1": "They are less parallelizable than grid search and random search.", "2": "They generate all candidate points up front and evaluate the batch in parallel.", "3": "They require more computation time than random search.", "4": "They do not model the response surface with another function."}, "Answer": "1", "Reason": "Smart hyperparameter tuning methods are less parallelizable than grid search and random search because they pick a few hyperparameter settings, evaluate their quality, and then decide where to sample next, which is an inherently iterative and sequential process."}, {"Question": "Which of the following is true about smart hyperparameter tuning methods?", "Options": {"1": "They are highly parallelizable.", "2": "They are always more computationally expensive than grid search.", "3": "They cannot be applied to problems where the evaluation procedure is faster than finding the next set of samples.", "4": "They require tuning their own parameters (hyper-hyperparameters)."}, "Answer": "4", "Reason": "Smart search algorithms require computation time to figure out where to place the next set of samples. They contain parameters of their own that need to be tuned, which can be crucial to make them faster than random search."}, {"Question": "What is one reason why hyperparameter tuning is considered a difficult task?", "Options": {"1": "The minimum and maximum values must be guessed.", "2": "The quality of hyperparameters cannot be written down in a closed-form formula.", "3": "It requires a large number of grid points to be evaluated.", "4": "It is impossible to parallelize the process."}, "Answer": "2", "Reason": "Hyperparameter tuning involves optimizing a function that cannot be expressed mathematically, making it difficult to determine the optimal values."}, {"Question": "Which of the following tests allows a new model to be either better or worse than the original?", "Options": {"1": "One-sided test", "2": "Two-sided test", "3": "Fisher's exact test", "4": "Mann-Whitney U test"}, "Answer": "2", "Reason": "A two-sided test allows the new model to be either better or worse than the original."}, {"Question": "What is the formula for statistical power of a test?", "Options": {"1": "Significance level + (difference in metrics/number of observations)", "2": "Significance level * (difference in metrics/number of observations)", "3": "Power = 1 - (false negative rate)", "4": "Power = 1 - (false positive rate)"}, "Answer": "3", "Reason": "It is calculated as 1 - false negative rate, which is the probability of correctly identifying a positive result."}, {"Question": "What is the difference between a one-sided test and a two-sided test in A/B testing?", "Options": {"1": "A one-sided test only tests if the new model is better than the baseline, while a two-sided test tests if the new model is either better or worse than the baseline.", "2": "A two-sided test only tests if the new model is worse than the baseline, while a one-sided test tests if the new model is either better or worse than the baseline.", "3": "A one-sided test tests if the new model is better than the baseline, while a two-sided test tests if the new model is exactly the same as the baseline.", "4": "A two-sided test tests if the new model is worse than the baseline, while a one-sided test tests if the new model is exactly the same as the baseline."}, "Answer": "1", "Reason": "A one-sided test only tests if the new model is better than the baseline, while a two-sided test tests if the new model is either better or worse than the baseline. It allows for the new model to be either better or worse than the original."}, {"Question": "According to the text, which of the following is NOT a rule of thumb to mitigate the violation of t-test assumptions?", "Options": {"1": "Take the log transform if the metric is nonnegative and has a long tail.", "2": "Use the family of power transforms to stabilize the variance.", "3": "Use the negative binomial distribution for counts.", "4": "Use the Mann-Whitney U test if the distribution looks nowhere near a Gaussian."}, "Answer": "4", "Reason": "The Mann-Whitney U test is a nonparametric test that doesn't make the Gaussian assumption, while the other options are specific to mitigating the violation of t-test assumptions."}, {"Question": "What is the purpose of a nonparametric test in A/B testing?", "Options": {"1": "To make assumptions about the distribution of the data", "2": "To use a smaller sample size", "3": "To test for the significance of a difference without making assumptions about the distribution", "4": "To increase the power of the test"}, "Answer": "3", "Reason": "Nonparametric tests do not make assumptions about the distribution of the data, making them useful when the t-test assumptions are violated, such as when the distribution is not Gaussian or the variances are unequal."}, {"Question": "What is the probability of a false positive out of every 20 new models that don't improve the baseline when setting the false positive rate at 0.05?", "Options": {"1": "0", "2": "1", "3": "5", "4": "20"}, "Answer": "2", "Reason": "A false positive rate of 0.05 means that out of every 20 new models that don\u2019t improve the baseline, on average 1 of them will be falsely identified by the test as an improvement."}, {"Question": "Which of the following is a rule of thumb for mitigating the violation of t-test assumptions when the metric is nonnegative and has a long tail?", "Options": {"1": "Take the log transform.", "2": "Use the negative binomial distribution.", "3": "Calculate the mean.", "4": "None of the above"}, "Answer": "1", "Reason": "Taking the log transform can help stabilize the variance and make the distribution more Gaussian-like."}, {"Question": "When is a two-sided test required for A/B testing?", "Options": {"1": "When the new model is guaranteed to be better than the baseline.", "2": "When the new model can be either better or worse than the baseline.", "3": "When the consequences of the new model being worse are negligible.", "4": "When the significance level is set to 0.05."}, "Answer": "2", "Reason": "A two-sided test allows for the possibility that the new model can be either better or worse than the baseline, which is a more comprehensive scenario."}, {"Question": "What is the probability of false positives when the significance level is set to 0.05?", "Options": {"1": "1 in 10", "2": "1 in 20", "3": "1 in 50", "4": "1 in 100"}, "Answer": "2", "Reason": "Out of every 20 new models that don\u2019t improve the baseline, on average 1 of them will be falsely identified by the test as an improvement."}, {"Question": "Which of the following distribution assumptions is made by the t-test?", "Options": {"1": "Gaussian distribution", "2": "Binomial distribution", "3": "Poisson distribution", "4": "Exponential distribution"}, "Answer": "1", "Reason": "The t-test assumes that the two populations being compared are Gaussian distributed."}, {"Question": "What is the alternative testing framework to A/B testing that focuses on maximizing total reward?", "Options": {"1": "P-value testing", "2": "Multiarmed bandits", "3": "Bootstrap testing", "4": "Bayesian testing"}, "Answer": "2", "Reason": "Multiarmed bandits are used to optimize total reward, rather than determine the best model or design."}, {"Question": "If a sample size is large enough, what is a good approximation for its distribution?", "Options": {"1": "Binomial", "2": "Poisson", "3": "Gaussian", "4": "Chi-Square"}, "Answer": "3", "Reason": "For large sample sizes, the distribution of a sample tends to approach the Gaussian distribution, which is also known as the normal distribution."}, {"Question": "What is a method for dealing with false positives in multiple tests?", "Options": {"1": "Bonferroni correction", "2": "Benjamini-Hochberg procedure", "3": "Tukey's test", "4": "Student's t-test"}, "Answer": "2", "Reason": "The Benjamini-Hochberg procedure orders the p-values from each test and rejects the null hypothesis for the smallest i normalized p-values, controlling the false discovery rate."}, {"Question": "Which of the following is NOT a factor that affects the interpretation of a p-value?", "Options": {"1": "Sample size", "2": "Difference between the two populations", "3": "Standard deviation", "4": "Confidence interval of the population mean estimates"}, "Answer": "3", "Reason": "A p-value is not affected by the standard deviation."}, {"Question": "Which of the following is NOT a potential downfall of A/B testing?", "Options": {"1": "False positive rate", "2": "Distribution drift", "3": "Novelty effects", "4": "Statistical significance"}, "Answer": "4", "Reason": "Statistical significance is a goal of A/B testing, not a downfall."}, {"Question": "The Benjamini-Hochberg procedure is used for controlling false positives in:", "Options": {"1": "Sequential analysis", "2": "Multiple hypothesis testing", "3": "A/B testing", "4": "Novelty effect analysis"}, "Answer": "2", "Reason": "The Benjamini-Hochberg procedure is a method for controlling the false discovery rate in multiple hypothesis testing, which occurs when numerous hypotheses are tested simultaneously."}, {"Question": "When is the Gaussian approximation for the distribution of the sample mean well approximated?", "Options": {"1": "When the sample sizes are larger than 20", "2": "When the sample size is less than 20", "3": "When the variance is equal", "4": "When the variance is not equal"}, "Answer": "1", "Reason": "The Gaussian approximation for the distribution of the sample mean is well approximated when the sample sizes are larger than 20."}, {"Question": "What is the Benjamini-Hochberg procedure used for?", "Options": {"1": "Controlling false discovery rate in multiple tests", "2": "Determining the length of an A/B test", "3": "Fixing a small sample size in an A/B test", "4": "Calculating the p-value for a single hypothesis test"}, "Answer": "1", "Reason": "The Benjamini-Hochberg procedure is a method for controlling the false discovery rate (FDR) in multiple hypothesis testing, which is useful when there are multiple models or hypotheses being tested simultaneously."}, {"Question": "What is the key assumption that is often made by many machine learning models?", "Options": {"1": "The data is normally distributed", "2": "The data is stationary", "3": "The data is independent", "4": "The data is linear"}, "Answer": "2", "Reason": "Machine learning models often assume that the data they are trained on is stationary, meaning that it looks and behaves one way for all eternity."}, {"Question": "What is the correct interpretation of a small p-value?", "Options": {"1": "A significant result", "2": "A more significant result", "3": "Both of the above", "4": "None of the above"}, "Answer": "4", "Reason": "A small p-value does not imply a significant result or a more significant result. It is a function of sample size, difference between populations, and variance estimation."}, {"Question": "Which of the following is a tool for bandit algorithms?", "Options": {"1": "Python", "2": "Matlab", "3": "R", "4": "All of the above"}, "Answer": "4", "Reason": "Bandit algorithms can be implemented in any programming language, so all of the above can be used as tools for bandit algorithms."}, {"Question": "What is the name of the statistical approach used to control the number of false positives in multiple hypothesis testing?", "Options": {"1": "Thompson sampling", "2": "False discovery rate", "3": "Negative binomial distribution", "4": "Contextual bandits"}, "Answer": "2", "Reason": "False discovery rate is a statistical approach used to control the proportion of false positives among the rejected hypotheses."}, {"Question": "Which of the following is a method for controlling the false discovery rate?", "Options": {"1": "Benjamini-Hochberg procedure", "2": "Dunn-Sidak procedure", "3": "Bonferroni correction", "4": "Tukey's HSD test"}, "Answer": "1", "Reason": "The Benjamini-Hochberg procedure is specifically designed to control the expected proportion of false discoveries among the rejected hypotheses."}, {"Question": "Which of the following is a common pitfall of A/B testing?", "Options": {"1": "Ignoring the importance of statistical significance", "2": "Assuming that all results are reliable", "3": "Overfitting your models", "4": "Not considering context or bias"}, "Answer": "2", "Reason": "Assuming that all results are reliable, regardless of statistical significance, is a common pitfall of A/B testing. It's important to consider the statistical significance of results to ensure that they are not due to chance."}, {"Question": "In the context of A/B testing, how does the false discovery rate (FDR) affect the significance level of hypothesis tests?", "Options": {"1": "It decreases the significance level, making it more likely to reject the null hypothesis.", "2": "It increases the significance level, making it less likely to reject the null hypothesis.", "3": "It has no effect on the significance level.", "4": "It affects the significance level only if the null hypothesis is true."}, "Answer": "1", "Reason": "The FDR controls the expected proportion of rejected hypotheses that are false positives, so it affects the significance level of hypothesis tests by making it more likely to reject the null hypothesis, even when it is true."}, {"Question": "Which of the following is a common pitfall in A/B testing?", "Options": {"1": "Not using a control group", "2": "Running the experiment for too short a time", "3": "Not considering the possibility of false positives", "4": "All of the above"}, "Answer": "4", "Reason": "All of the options are common pitfalls in A/B testing. Not using a control group makes it difficult to determine the effect of the intervention, running the experiment for too short a time may not give enough data to draw meaningful conclusions, and not considering the possibility of false positives can lead to overestimating the effect of the intervention."}, {"Question": "Which of the following is NOT a benefit of using A/B testing?", "Options": {"1": "Reduced risk of false positives", "2": "Improved data quality", "3": "Increased traffic on website", "4": "Customized user experience"}, "Answer": "3", "Reason": "A/B testing is designed to help determine which version of a website or app is more effective, it doesn't directly increase traffic to a website."}, {"Question": "What tool is best to avoid many unhappy incidents on the way to machine learning-izing your world?", "Options": {"1": "A/B testing", "2": "Thompson sampling", "3": "Bandit algorithms", "4": "False discovery rate"}, "Answer": "3", "Reason": "Bandit algorithms are explicitly mentioned as a way to avoid unhappy incidents in the text."}, {"Question": "According to the text, what is a key challenge in A/B testing?", "Options": {"1": "Trustworthy online controlled experiments", "2": "Multiple testing", "3": "Bandit algorithms", "4": "Personalization via contextual bandits"}, "Answer": "2", "Reason": "The text mentions multiple testing as a challenge in A/B testing, as it can lead to false positives and false negatives."}, {"Question": "Which of the following is a potential pitfall of A/B testing?", "Options": {"1": "Confounding variables", "2": "Simpson's paradox", "3": "Selection bias", "4": "All of the above"}, "Answer": "4", "Reason": "Confounding variables, Simpson's paradox, and selection bias are all potential pitfalls of A/B testing that can lead to incorrect conclusions being drawn."}]